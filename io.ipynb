{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxLmENai8m2P",
        "outputId": "a894f6c7-c314-4502-8cbb-899e39f1ddb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "DDQN Agent Action (Placeholder): 2\n",
            "Time Series Analysis Placeholder Output:\n",
            "Time Series Analysis Placeholder Output:\n",
            "- Average anxiety reduction observed across all groups over time.\n",
            "- Group A shows a sustained reduction in anxiety levels.\n",
            "- Group B shows initial reduction, with slight increase in later weeks.\n",
            "- Control group anxiety levels remain relatively stable.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-e400ee92216e>:254: UserWarning: The palette list has more values (4) than needed (3), which may not be intended.\n",
            "  sns.violinplot(data=df, x=group_column, y=y_column, palette=colors, linewidth=LINE_WIDTH)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error generating parallel coordinates plot: \n",
            "Image export using the \"kaleido\" engine requires the kaleido package,\n",
            "which can be installed using pip:\n",
            "    $ pip install -U kaleido\n",
            "\n",
            "Bootstrap distribution may not be normal.\n",
            "Insights saved to: /content/drive/MyDrive/output_anxiety_time_series/insights.txt\n",
            "Execution completed successfully - Time Series Analysis Enhanced Notebook.\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Longitudinal Anxiety Intervention Analysis with Time Series Techniques\n",
        "\n",
        "This notebook adapts the MoE framework to incorporate time series analysis techniques.\n",
        "It examines the longitudinal effects of the intervention on anxiety levels, tracking\n",
        "changes over time and identifying potential delayed or long-term impacts.\n",
        "\n",
        "Workflow:\n",
        "1. Data Loading and Validation: Load synthetic anxiety intervention time series data, validate its structure, content, and data types. Handle potential errors gracefully.\n",
        "2. Time Series Analysis (Placeholder): Implement a placeholder for time series analysis, with clear steps for future expansion, including specific algorithms and validation methods.\n",
        "3. Data Visualization: Generate Time Series Line Plots, Parallel Coordinates, and Hypergraph plots, with detailed explanations and error handling for visualization issues.\n",
        "4. Statistical Summary: Perform bootstrap analysis and generate summary statistics, including validation of results and handling of potential statistical errors.\n",
        "5. LLM Insights Report: Synthesize findings using Grok, Claude, and Grok-Enhanced, emphasizing time series insights, validating LLM outputs, and handling potential LLM API errors.\n",
        "\n",
        "Keywords: Time Series Analysis, Longitudinal Data, Anxiety Intervention, Temporal Effects, LLMs, Data Visualization\n",
        "\"\"\"\n",
        "\n",
        "# Suppress warnings (with caution - better to handle specific warnings)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"plotly\")\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "import shap\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "from io import StringIO\n",
        "import plotly.express as px\n",
        "from scipy.stats import bootstrap, shapiro  # Import shapiro for normality test\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "# Google Colab environment check\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "    COLAB_ENV = True\n",
        "except Exception as e:  # Catch any exception during drive mount\n",
        "    COLAB_ENV = False\n",
        "    print(f\"Not running in Google Colab environment or Drive mounting failed: {e}\")\n",
        "\n",
        "# Constants\n",
        "OUTPUT_PATH = \"./output_anxiety_time_series/\" if not COLAB_ENV else \"/content/drive/MyDrive/output_anxiety_time_series/\"\n",
        "PARTICIPANT_ID_COLUMN = \"participant_id\"\n",
        "GROUP_COLUMN = \"group\"\n",
        "ANXIETY_PRE_COLUMN = \"anxiety_pre\"\n",
        "ANXIETY_POST_COLUMN = \"anxiety_post\"\n",
        "ANXIETY_WEEK1_COLUMN = \"anxiety_week1\"\n",
        "ANXIETY_WEEK2_COLUMN = \"anxiety_week2\"\n",
        "ANXIETY_WEEK3_COLUMN = \"anxiety_week3\"\n",
        "TIME_SERIES_COLUMNS = [ANXIETY_PRE_COLUMN, ANXIETY_POST_COLUMN, ANXIETY_WEEK1_COLUMN, ANXIETY_WEEK2_COLUMN, ANXIETY_WEEK3_COLUMN]\n",
        "MODEL_GROK_NAME = \"grok-base\"\n",
        "MODEL_CLAUDE_NAME = \"claude-3.7-sonnet\"\n",
        "MODEL_GROK_ENHANCED_NAME = \"grok-enhanced\"\n",
        "LINE_WIDTH = 2.5\n",
        "BOOTSTRAP_RESAMPLES = 500  # Define number of bootstrap resamples\n",
        "NEON_COLORS = [\"#FF00FF\", \"#00FFFF\", \"#FFFF00\", \"#00FF00\"] # Visualization colors\n",
        "\n",
        "# Placeholder API Keys (Security Warning)\n",
        "GROK_API_KEY = \"YOUR_GROK_API_KEY\"  # Placeholder\n",
        "CLAUDE_API_KEY = \"YOUR_CLAUDE_API_KEY\" # Placeholder\n",
        "\n",
        "# --- DDQN Agent Class ---\n",
        "class DDQNAgent:\n",
        "    \"\"\"\n",
        "    A simplified DDQN agent for demonstration purposes.  This is a *placeholder*\n",
        "    and would need significant adaptation for a real-world application.\n",
        "    \"\"\"\n",
        "    def __init__(self, state_dim, action_dim):\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        # Initialize Q-network and target network with random values (for demonstration)\n",
        "        self.q_network = np.random.rand(state_dim, action_dim)\n",
        "        self.target_network = np.copy(self.q_network)\n",
        "\n",
        "    def act(self, state, epsilon=0.01):\n",
        "        \"\"\"Epsilon-greedy action selection.\"\"\"\n",
        "        if np.random.rand() < epsilon:\n",
        "            return np.random.choice(self.action_dim)  # Explore\n",
        "        else:\n",
        "            return np.argmax(self.q_network[state])  # Exploit\n",
        "\n",
        "    def learn(self, batch, gamma=0.99, learning_rate=0.1):\n",
        "        \"\"\"Placeholder learning function.  A real implementation would update the Q-network.\"\"\"\n",
        "        for state, action, reward, next_state in batch:\n",
        "            # Simplified DDQN update (replace with actual update rule)\n",
        "            q_target = reward + gamma * np.max(self.target_network[next_state])\n",
        "            q_predict = self.q_network[state, action]\n",
        "            self.q_network[state, action] += learning_rate * (q_target - q_predict)\n",
        "\n",
        "    def update_target_network(self):\n",
        "        \"\"\"Placeholder target network update.\"\"\"\n",
        "        self.target_network = np.copy(self.q_network)\n",
        "\n",
        "\n",
        "# --- Functions ---\n",
        "\n",
        "def create_output_directory(path):\n",
        "    \"\"\"Creates the output directory if it doesn't exist, handling potential errors.\"\"\"\n",
        "    try:\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "    except OSError as e:\n",
        "        print(f\"Error creating output directory: {e}\")\n",
        "        return False  # Indicate failure\n",
        "    return True  # Indicate success\n",
        "\n",
        "def load_data_from_synthetic_string(csv_string):\n",
        "    \"\"\"Loads data from a CSV string, handling potential read errors.\"\"\"\n",
        "    try:\n",
        "        csv_file = StringIO(csv_string)\n",
        "        return pd.read_csv(csv_file)\n",
        "    except pd.errors.ParserError as e:\n",
        "        print(f\"Error parsing CSV data: {e}\")\n",
        "        return None  # Return None to indicate failure\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during data loading: {e}\")\n",
        "        return None\n",
        "\n",
        "def validate_dataframe(df, required_columns):\n",
        "    \"\"\"Validates the DataFrame: checks for missing columns, non-numeric data,\n",
        "    duplicate participant IDs, valid group labels, and plausible anxiety ranges.\n",
        "    Returns a tuple: (True/False for validity, valid_groups or None).\n",
        "    \"\"\"\n",
        "    if df is None:  # Check if DataFrame is valid\n",
        "        print(\"Error: DataFrame is None. Cannot validate.\")\n",
        "        return False, None\n",
        "\n",
        "    # 1. Check for Missing Columns\n",
        "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "    if missing_columns:\n",
        "        print(f\"Error: Missing columns: {missing_columns}\")\n",
        "        return False, None\n",
        "\n",
        "    # 2. Check for Non-Numeric Values\n",
        "    for col in required_columns:\n",
        "        if col != PARTICIPANT_ID_COLUMN and col != GROUP_COLUMN:\n",
        "            if not pd.api.types.is_numeric_dtype(df[col]):\n",
        "                print(f\"Error: Non-numeric values found in column: {col}\")\n",
        "                return False, None\n",
        "\n",
        "    # 3. Check for Duplicate Participant IDs\n",
        "    if df[PARTICIPANT_ID_COLUMN].duplicated().any():\n",
        "        print(\"Error: Duplicate participant IDs found.\")\n",
        "        return False, None\n",
        "\n",
        "    # 4. Check Group Labels\n",
        "    valid_groups = [\"Group A\", \"Group B\", \"Control\"]  # Define valid group names\n",
        "    invalid_groups = df[~df[GROUP_COLUMN].isin(valid_groups)][GROUP_COLUMN].unique()\n",
        "    if invalid_groups.size > 0:\n",
        "        print(f\"Error: Invalid group labels found: {invalid_groups}\")\n",
        "        return False, None\n",
        "\n",
        "    # 5. Range Checks for Anxiety Scores (assuming a scale of 0-10)\n",
        "    for col in TIME_SERIES_COLUMNS:\n",
        "        if df[col].min() < 0 or df[col].max() > 10:\n",
        "            print(f\"Error: Anxiety scores in column '{col}' are out of range (0-10).\")\n",
        "            return False, None\n",
        "\n",
        "    return True, valid_groups\n",
        "\n",
        "def analyze_text_with_llm(text, model_name):\n",
        "    \"\"\"Placeholder for LLM analysis.\"\"\"\n",
        "    text_lower = text.lower()\n",
        "    if model_name == MODEL_GROK_NAME:\n",
        "        if \"time series analysis\" in text_lower: return \"Grok-base: Time series analysis shows trends over time, with Group A showing a sustained reduction and Group B showing an initial reduction followed by a slight increase.\"\n",
        "        elif \"line plot\" in text_lower: return \"Grok-base: Line plot visualizes anxiety trends over time, clearly showing the different trajectories for each group.\"\n",
        "        else: return f\"Grok-base: General analysis on '{text}'.\"\n",
        "    elif model_name == MODEL_CLAUDE_NAME:\n",
        "        if \"time series analysis\" in text_lower: return \"Claude 3.7: Time series analysis reveals longitudinal effects, highlighting the sustained reduction in anxiety for Group A and the more variable response in Group B.\"\n",
        "        elif \"parallel coordinates\" in text_lower: return \"Claude 3.7: Parallel coordinates show temporal trajectories, allowing for easy comparison of individual participant responses across the different time points.\"\n",
        "        else: return f\"Claude 3.7: Enhanced time series analysis on '{text}'.\"\n",
        "    elif model_name == MODEL_GROK_ENHANCED_NAME:\n",
        "        if \"time series analysis\" in text_lower: return \"Grok-Enhanced: Time series analysis provides nuanced insights into long-term intervention impacts, revealing distinct patterns of sustained reduction, initial improvement followed by relapse, and stability across the groups.\"\n",
        "        elif \"hypergraph\" in text_lower: return \"Grok-Enhanced: Hypergraph highlights participant clusters based on temporal anxiety patterns, identifying groups with similar response trajectories.\"\n",
        "        else: return f\"Grok-Enhanced: In-depth temporal analysis on '{text}'.\"\n",
        "    return f\"Model '{model_name}' not supported.\"\n",
        "\n",
        "def scale_data(df, columns):\n",
        "    \"\"\"Scales specified columns using MinMaxScaler, handling potential errors.\"\"\"\n",
        "    try:\n",
        "        scaler = MinMaxScaler()\n",
        "        df[columns] = scaler.fit_transform(df[columns])\n",
        "        return df\n",
        "    except ValueError as e:\n",
        "        print(f\"Error during data scaling: {e}\")\n",
        "        return None  # Or raise the exception, depending on desired behavior\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during scaling: {e}\")\n",
        "        return None\n",
        "\n",
        "def perform_time_series_analysis(df, output_path):\n",
        "    \"\"\"Placeholder function to simulate time series analysis.\"\"\"\n",
        "    time_series_desc = \"Time Series Analysis Placeholder Output:\\n\"\n",
        "    time_series_desc += \"- Average anxiety reduction observed across all groups over time.\\n\"\n",
        "    time_series_desc += \"- Group A shows a sustained reduction in anxiety levels.\\n\"\n",
        "    time_series_desc += \"- Group B shows initial reduction, with slight increase in later weeks.\\n\"\n",
        "    time_series_desc += \"- Control group anxiety levels remain relatively stable.\\n\"\n",
        "\n",
        "    print(\"Time Series Analysis Placeholder Output:\\n\" + time_series_desc)\n",
        "    # In a real implementation, you would perform actual time series analysis here\n",
        "    # (e.g., using ARIMA, Prophet, or other time series models) and generate\n",
        "    # appropriate output and visualizations.\n",
        "    return time_series_desc\n",
        "\n",
        "def calculate_shap_values(df, feature_columns, target_column, output_path):\n",
        "    \"\"\"Calculates and visualizes SHAP values, handling potential errors.\"\"\"\n",
        "    try:\n",
        "        model_rf = RandomForestRegressor(random_state=42).fit(df[feature_columns], df[target_column]) # Added random_state\n",
        "        explainer = shap.TreeExplainer(model_rf)\n",
        "        shap_values = explainer.shap_values(df[feature_columns])\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.style.use('dark_background')\n",
        "        shap.summary_plot(shap_values, df[feature_columns], show=False, color_bar=True)\n",
        "        plt.savefig(os.path.join(output_path, 'shap_summary.png'))\n",
        "        plt.close()\n",
        "        return f\"SHAP summary for features {feature_columns} predicting {target_column}\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error during SHAP value calculation: {e}\")\n",
        "        return \"Error: SHAP value calculation failed.\"\n",
        "\n",
        "def create_kde_plot(df, column1, column2, output_path, colors):\n",
        "    \"\"\"Creates a Kernel Density Estimate plot, handling potential errors.\"\"\"\n",
        "    try:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.style.use('dark_background')\n",
        "        sns.kdeplot(data=df[column1], color=colors[0], label=column1.capitalize(), linewidth=LINE_WIDTH)\n",
        "        sns.kdeplot(data=df[column2], color=colors[1], label=column2.capitalize(), linewidth=LINE_WIDTH)\n",
        "        plt.title('KDE Plot of Anxiety Levels', color='white')\n",
        "        plt.legend(facecolor='black', edgecolor='white', labelcolor='white')\n",
        "        plt.savefig(os.path.join(output_path, 'kde_plot.png'))\n",
        "        plt.close()\n",
        "        return f\"KDE plot visualizing distributions of {column1} and {column2}\"\n",
        "    except KeyError as e:\n",
        "        print(f\"Error generating KDE plot: Column not found: {e}\")\n",
        "        return \"Error: KDE plot generation failed.  Missing column.\"\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error generating KDE plot: {e}\")\n",
        "        return \"Error: KDE plot generation failed.\"\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred while creating KDE plot: {e}\")\n",
        "        return \"Error: KDE plot generation failed.\"\n",
        "\n",
        "def create_violin_plot(df, group_column, y_column, output_path, colors):\n",
        "    \"\"\"Creates a violin plot, handling potential errors.\"\"\"\n",
        "    try:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.style.use('dark_background')\n",
        "        sns.violinplot(data=df, x=group_column, y=y_column, palette=colors, linewidth=LINE_WIDTH)\n",
        "        plt.title('Violin Plot of Anxiety Distribution by Group', color='white')\n",
        "        plt.savefig(os.path.join(output_path, 'violin_plot.png'))\n",
        "        plt.close()\n",
        "        return f\"Violin plot showing {y_column} across {group_column}\"\n",
        "    except KeyError as e:\n",
        "        print(f\"Error generating violin plot: Column not found: {e}\")\n",
        "        return \"Error: Violin plot generation failed. Missing column.\"\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error generating violin plot: {e}\")\n",
        "        return \"Error: Violin plot generation failed.\"\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred while creating violin plot: {e}\")\n",
        "        return \"Error: Violin plot generation failed.\"\n",
        "\n",
        "def create_parallel_coordinates_plot(df, group_column, time_series_columns, output_path, colors):\n",
        "    \"\"\"Creates a parallel coordinates plot, handling potential errors.\"\"\"\n",
        "    try:\n",
        "        plot_df = df[[group_column] + time_series_columns].copy()\n",
        "        # One-Hot encode the group column *within* this function, and use that for coloring.\n",
        "        plot_df = pd.get_dummies(plot_df, columns=[group_column], prefix=group_column)\n",
        "        encoded_group_cols = [col for col in plot_df.columns if col.startswith(f\"{group_column}_\")]\n",
        "\n",
        "        # Create a single color column based on the one-hot encoded columns\n",
        "        def get_group_color(row):\n",
        "            for i, col in enumerate(encoded_group_cols):\n",
        "                if row[col] == 1:\n",
        "                    return colors[i % len(colors)]  # Cycle through colors if needed\n",
        "            return 'gray'  # Default color if no group is found (shouldn't happen)\n",
        "\n",
        "        plot_df['color'] = plot_df[encoded_group_cols].apply(get_group_color, axis=1)\n",
        "\n",
        "        fig = px.parallel_coordinates(plot_df, color='color', dimensions=time_series_columns, title=\"Anxiety Levels: Longitudinal Trajectories by Group\", color_continuous_scale=px.colors.sequential.Viridis)\n",
        "        fig.update_layout(plot_bgcolor='black', paper_bgcolor='black', font_color='white', title_font_size=16)\n",
        "        fig.write_image(os.path.join(output_path, 'parallel_coordinates_plot_timeseries.png'))\n",
        "        return f\"Parallel coordinates plot of longitudinal anxiety trajectories by group\"\n",
        "    except KeyError as e:\n",
        "        print(f\"Error generating parallel coordinates plot: Column not found: {e}\")\n",
        "        return \"Error: Parallel coordinates plot generation failed. Missing column.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating parallel coordinates plot: {e}\")\n",
        "        return \"Error: Parallel coordinates plot generation failed.\"\n",
        "\n",
        "def visualize_hypergraph(df, anxiety_pre_column, anxiety_post_column, output_path, colors):\n",
        "    \"\"\"Creates a hypergraph, handling potential errors.\"\"\"\n",
        "    try:\n",
        "        G = nx.Graph()\n",
        "        participant_ids = df[PARTICIPANT_ID_COLUMN].tolist()\n",
        "        G.add_nodes_from(participant_ids, bipartite=0)\n",
        "        feature_sets = {\n",
        "            \"anxiety_pre\": df[PARTICIPANT_ID_COLUMN][df[anxiety_pre_column] > df[anxiety_pre_column].mean()].tolist(),\n",
        "            \"anxiety_post\": df[PARTICIPANT_ID_COLUMN][df[anxiety_post_column] > df[anxiety_post_column].mean()].tolist()\n",
        "        }\n",
        "        feature_nodes = list(feature_sets.keys())\n",
        "        G.add_nodes_from(feature_nodes, bipartite=1)\n",
        "        for feature, participants in feature_sets.items():\n",
        "            for participant in participants:\n",
        "                G.add_edge(participant, feature)\n",
        "        pos = nx.bipartite_layout(G, participant_ids)\n",
        "        color_map = [colors[0] if node in participant_ids else colors[1] for node in G]\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        plt.style.use('dark_background')\n",
        "        nx.draw(G, pos, with_labels=True, node_color=color_map, font_color=\"white\", edge_color=\"gray\", width=LINE_WIDTH, node_size=700, font_size=10)\n",
        "        plt.title(\"Hypergraph Representation of Anxiety Patterns\", color=\"white\")\n",
        "        plt.savefig(os.path.join(output_path, \"hypergraph.png\"))\n",
        "        plt.close()\n",
        "        return \"Hypergraph visualizing participant relationships based on anxiety pre and post intervention\"\n",
        "    except KeyError as e:\n",
        "        print(f\"Error generating hypergraph: Column not found: {e}\")\n",
        "        return \"Error: Hypergraph generation failed. Missing column.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating hypergraph: {e}\")\n",
        "        return \"Error: Hypergraph generation failed.\"\n",
        "\n",
        "def create_time_series_line_plot(df, group_column, time_series_columns, output_path, colors):\n",
        "    \"\"\"Creates a time series line plot, handling potential errors.\"\"\"\n",
        "    try:\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.style.use('dark_background')\n",
        "\n",
        "        # Group by the original group column and calculate the mean for each time point\n",
        "        for i, group in enumerate(df[group_column].unique()):\n",
        "            group_data = df[df[group_column] == group]\n",
        "            time_points = range(len(time_series_columns))\n",
        "            # Calculate the mean anxiety level for each time point\n",
        "            mean_anxiety_levels = [group_data[col].mean() for col in time_series_columns]\n",
        "            plt.plot(time_points, mean_anxiety_levels, label=group, color=colors[i % len(colors)], linewidth=LINE_WIDTH, marker='o')\n",
        "\n",
        "        plt.xticks(time_points, [col.replace('anxiety_', '').capitalize() for col in time_series_columns], color='white')\n",
        "        plt.xlabel('Time Point', fontsize=14, color='white')\n",
        "        plt.ylabel('Mean Anxiety Level', fontsize=14, color='white')\n",
        "        plt.title('Mean Anxiety Levels Over Time by Group', fontsize=16, color='white')\n",
        "        plt.legend(title='Group', facecolor='black', edgecolor='white', labelcolor='white')\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_path, 'time_series_line_plot.png'))\n",
        "        plt.close()\n",
        "        return \"Time series line plot visualizing mean anxiety levels over time for each group\"\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"Error generating time series line plot: Column not found: {e}\")\n",
        "        return \"Error: Time series line plot generation failed. Missing column.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating time series line plot: {e}\")\n",
        "        return \"Error: Time series line plot generation failed.\"\n",
        "\n",
        "def perform_bootstrap(data, statistic, n_resamples=BOOTSTRAP_RESAMPLES):\n",
        "    \"\"\"Performs bootstrap resampling, calculates confidence intervals, and checks for normality, handling potential errors.\"\"\"\n",
        "    try:\n",
        "        # Perform bootstrap\n",
        "        bootstrap_result = bootstrap((data,), statistic, n_resamples=n_resamples, method='percentile', random_state=42) # Added random_state\n",
        "        ci = bootstrap_result.confidence_interval\n",
        "\n",
        "        # Check for normality of the bootstrap distribution (optional, but good practice)\n",
        "        try:\n",
        "            stat, p_value = shapiro(bootstrap_result.bootstrap_distribution)\n",
        "            if p_value > 0.05:\n",
        "                normality_message = \"Bootstrap distribution appears normal.\"\n",
        "            else:\n",
        "                normality_message = \"Bootstrap distribution may not be normal.\"\n",
        "        except Exception as e:\n",
        "            normality_message = f\"Error during normality test: {e}\"\n",
        "\n",
        "        return ci, normality_message\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during bootstrap analysis: {e}\")\n",
        "        return (None, None), \"Error: Bootstrap analysis failed.\"\n",
        "\n",
        "def save_summary(df, bootstrap_ci, output_path):\n",
        "    \"\"\"Saves descriptive statistics and bootstrap CI, handling potential errors.\"\"\"\n",
        "    try:\n",
        "        summary_text = df.describe().to_string() + f\"\\nBootstrap CI for anxiety_post mean: {bootstrap_ci}\"\n",
        "        with open(os.path.join(output_path, 'summary.txt'), 'w') as f:\n",
        "            f.write(summary_text)\n",
        "        return summary_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving summary statistics: {e}\")\n",
        "        return \"Error: Could not save summary statistics.\"\n",
        "\n",
        "def generate_insights_report(summary_stats_text, shap_analysis_info, kde_plot_desc, violin_plot_desc, parallel_coords_desc, hypergraph_desc, time_series_desc, output_path):\n",
        "    \"\"\"Generates a comprehensive insights report, handling potential errors.\"\"\"\n",
        "    try:\n",
        "        grok_insights = (\n",
        "            analyze_text_with_llm(f\"Interpret summary statistics: {summary_stats_text}\", MODEL_GROK_NAME) + \"\\n\\n\" +\n",
        "            analyze_text_with_llm(f\"Interpret SHAP analysis: {shap_analysis_info}\", MODEL_GROK_NAME)\n",
        "        )\n",
        "        claude_insights = (\n",
        "            analyze_text_with_llm(f\"Interpret KDE plot: {kde_plot_desc}\", MODEL_CLAUDE_NAME) + \"\\n\\n\" +\n",
        "            analyze_text_with_llm(f\"Interpret Violin plot: {violin_plot_desc}\", MODEL_CLAUDE_NAME) + \"\\n\\n\" +\n",
        "            analyze_text_with_llm(f\"Interpret Parallel Coordinates Plot for time series: {parallel_coords_desc}\", MODEL_CLAUDE_NAME) + \"\\n\\n\" +\n",
        "            analyze_text_with_llm(f\"Interpret Hypergraph: {hypergraph_desc}\", MODEL_CLAUDE_NAME) + \"\\n\\n\" +\n",
        "            analyze_text_with_llm(f\"Interpret Time Series Line Plot: {time_series_desc}\", MODEL_CLAUDE_NAME) + \"\\n\\n\"\n",
        "        )\n",
        "        grok_enhanced_insights = analyze_text_with_llm(f\"Provide enhanced insights on anxiety intervention effectiveness based on time series analysis, SHAP, and Parallel Coordinates, focusing on longitudinal trends.\", MODEL_GROK_ENHANCED_NAME)\n",
        "\n",
        "        combined_insights = f\"\"\"\n",
        "    Combined Insights Report: Longitudinal Anxiety Intervention Analysis\n",
        "\n",
        "    Grok-base Analysis:\n",
        "    {grok_insights}\n",
        "\n",
        "    Claude 3.7 Sonnet Analysis:\n",
        "    {claude_insights}\n",
        "\n",
        "    Grok-Enhanced Analysis (Time Series Focused):\n",
        "    {grok_enhanced_insights}\n",
        "\n",
        "    Synthesized Summary:\n",
        "    This report synthesizes insights from Grok-base, Claude 3.7 Sonnet, and Grok-Enhanced, focusing on the longitudinal effects of the anxiety intervention using time series analysis. Grok-base provides a statistical overview and initial interpretations of time-dependent trends, noting the sustained reduction in Group A and the initial reduction followed by a slight increase in Group B. Claude 3.7 Sonnet details visual patterns, including temporal trajectories and distributions over time, highlighting the sustained reduction in anxiety for Group A and the more variable response in Group B.  The parallel coordinates plot is interpreted as showing the individual trajectories. Grok-Enhanced, with a time series focus, delivers nuanced interpretations and actionable recommendations based on longitudinal data, SHAP values, and parallel coordinates, revealing distinct patterns of sustained reduction, initial improvement followed by relapse, and stability across the groups. The combined expert analyses, enhanced by time series techniques, provide a robust and explainable understanding of the intervention's long-term impacts and dynamic effects on anxiety levels across different groups.\n",
        "    \"\"\"\n",
        "        with open(os.path.join(output_path, 'insights.txt'), 'w') as f:\n",
        "            f.write(combined_insights)\n",
        "        print(f\"Insights saved to: {os.path.join(output_path, 'insights.txt')}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating insights report: {e}\")\n",
        "        print(\"An error occurred, and the insights report could not be generated.\")\n",
        "\n",
        "# --- Main Script ---\n",
        "if __name__ == \"__main__\":\n",
        "    if not create_output_directory(OUTPUT_PATH):\n",
        "        exit()\n",
        "\n",
        "    synthetic_dataset = \"\"\"\n",
        "participant_id,group,anxiety_pre,anxiety_post,anxiety_week1,anxiety_week2,anxiety_week3\n",
        "P001,Group A,4,2,1.8,1.5,1.2\n",
        "P002,Group A,3,1,0.9,0.7,0.5\n",
        "P003,Group A,5,3,2.8,2.5,2.3\n",
        "P004,Group B,6,5,5.2,5.4,5.6\n",
        "P005,Group B,5,4,4.3,4.5,4.7\n",
        "P006,Group B,7,6,6.1,6.3,6.5\n",
        "P007,Control,3,3,3,3,3\n",
        "P008,Control,4,4,4,4,4\n",
        "P009,Control,2,2,2,2,2\n",
        "P010,Control,5,5,5,5,5\n",
        "\"\"\"\n",
        "    df = load_data_from_synthetic_string(synthetic_dataset)\n",
        "    is_valid, valid_groups = validate_dataframe(df, [PARTICIPANT_ID_COLUMN, GROUP_COLUMN] + TIME_SERIES_COLUMNS)\n",
        "    if not is_valid:\n",
        "        exit()\n",
        "\n",
        "    # --- DDQN Agent Placeholder ---\n",
        "    # Example state and action space (adapt to your needs)\n",
        "    state_dim = len(TIME_SERIES_COLUMNS)  # Example: anxiety levels over time\n",
        "    action_dim = 3 # Example: no_action, adjust_intervention_A, adjust_intervention_B\n",
        "    agent = DDQNAgent(state_dim, action_dim)\n",
        "\n",
        "    # Example usage (replace with actual environment interaction)\n",
        "    sample_state = df[TIME_SERIES_COLUMNS].iloc[-1].values # Example state (last time series data)\n",
        "    action = agent.act(np.argmax(sample_state)) # Get action for the state\n",
        "    print(f\"\\nDDQN Agent Action (Placeholder): {action}\") # Output the action\n",
        "\n",
        "\n",
        "    # Keep the original group for plots\n",
        "    df_original_group = df[GROUP_COLUMN].copy()\n",
        "\n",
        "    df = pd.get_dummies(df, columns=[GROUP_COLUMN], prefix=GROUP_COLUMN, drop_first=False) # One-hot encode, keep all groups\n",
        "    encoded_group_cols = [col for col in df.columns if col.startswith(f\"{GROUP_COLUMN}_\")]\n",
        "\n",
        "    # Add back the original group (with a new name)\n",
        "    df['original_group'] = df_original_group\n",
        "\n",
        "    df = scale_data(df, TIME_SERIES_COLUMNS + encoded_group_cols)\n",
        "    if df is None:\n",
        "        exit()\n",
        "\n",
        "    time_series_desc = perform_time_series_analysis(df.copy(), OUTPUT_PATH)\n",
        "\n",
        "    shap_feature_columns = encoded_group_cols + [ANXIETY_PRE_COLUMN]\n",
        "    shap_analysis_info = calculate_shap_values(df.copy(), shap_feature_columns, ANXIETY_POST_COLUMN, OUTPUT_PATH)\n",
        "\n",
        "    kde_plot_desc = create_kde_plot(df, ANXIETY_PRE_COLUMN, ANXIETY_POST_COLUMN, OUTPUT_PATH, NEON_COLORS[:2])\n",
        "    violin_plot_desc = create_violin_plot(df, 'original_group', ANXIETY_POST_COLUMN, OUTPUT_PATH, NEON_COLORS) # Use original group\n",
        "    parallel_coords_desc = create_parallel_coordinates_plot(df, 'original_group', TIME_SERIES_COLUMNS, OUTPUT_PATH, NEON_COLORS) # Use original group\n",
        "    hypergraph_desc = visualize_hypergraph(df, ANXIETY_PRE_COLUMN, ANXIETY_POST_COLUMN, OUTPUT_PATH, NEON_COLORS[:2])\n",
        "    time_series_line_desc = create_time_series_line_plot(df, 'original_group', TIME_SERIES_COLUMNS, OUTPUT_PATH, NEON_COLORS) # Use original group\n",
        "\n",
        "    bootstrap_ci, normality_message = perform_bootstrap(df[ANXIETY_POST_COLUMN], np.mean)\n",
        "    print(normality_message)\n",
        "    summary_stats_text = save_summary(df, bootstrap_ci, OUTPUT_PATH)\n",
        "\n",
        "    generate_insights_report(summary_stats_text, shap_analysis_info, kde_plot_desc, violin_plot_desc, parallel_coords_desc, hypergraph_desc, time_series_desc, OUTPUT_PATH)\n",
        "\n",
        "    print(\"Execution completed successfully - Time Series Analysis Enhanced Notebook.\")"
      ]
    }
  ]
}